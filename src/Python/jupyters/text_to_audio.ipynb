{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "540e585b-c076-4102-a0a5-774e7fe8aaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install SpeechRecognition pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f789aef",
   "metadata": {},
   "source": [
    "# SPEECH de archivo WAV a TeXTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b251cb9d-45e3-4f5d-872b-fae9fef81c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "\n",
    "def mp3_to_text(mp3_file):\n",
    "    # Convertir MP3 a WAV\n",
    "    audio = AudioSegment.from_mp3(mp3_file)\n",
    "    wav_file = mp3_file.replace(\".mp3\", \".wav\")\n",
    "    print(wav_file)\n",
    "    audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "    # Reconocer el texto del archivo WAV\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(wav_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            return text\n",
    "        except sr.UnknownValueError:\n",
    "            return \"Google Speech Recognition no pudo entender el audio\"\n",
    "        except sr.RequestError as e:\n",
    "            return f\"Error al conectar con el servicio de Google Speech Recognition; {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f557d3cd-094b-4e8d-a055-379e84e83f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/AudiosFiles/p1_stories_1a.wav\n",
      "my name is Scott I am 7 years old I have two pens three pencils and one ruler I am sitting on my chair in my classroom there is a book on my desk\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso ingles\n",
    "mp3_file = r\"/media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/AudiosFiles/p1_stories_1a.mp3\"  # Reemplaza con la ruta a tu archivo MP3\n",
    "texto = mp3_to_text(mp3_file)\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a51f6f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp3_to_text_esp(mp3_file):\n",
    "    # Convertir MP3 a WAV\n",
    "    audio = AudioSegment.from_mp3(mp3_file)\n",
    "    wav_file = mp3_file.replace(\".mp3\", \".wav\")\n",
    "    print(wav_file)\n",
    "    audio.export(wav_file, format=\"wav\")\n",
    "\n",
    "    # Reconocer el texto del archivo WAV\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(wav_file) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data, language=\"es-ES\")\n",
    "            return text\n",
    "        \n",
    "        except sr.UnknownValueError:\n",
    "            return \"Google Speech Recognition no pudo entender el audio\"\n",
    "        except sr.RequestError as e:\n",
    "            return f\"Error al conectar con el servicio de Google Speech Recognition; {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc0dfdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/AudiosFiles//maximo_ventana_español.wav\n",
      "saludo Mi nombre es máximo soy de la República Dominicana actualmente vivo en un apartamento me gusta mucho mirar por la ventana o a través de la ventana ya que así puedo ver los vehículos pasando por ejemplo ahora mismo acaba de pasar un joven en una bicicleta paseando por las calles también podemos ver una pareja de ancianos puedo ver también a través de mi ventana Dónde hay un estacionamiento lo cual hay aproximadamente 5 carros estacionados también podemos ver diferentes edificios con diferente colores y diferentes diseños me gusta mirar por mi ventana ya que así puedo ver todo lo que pasa durante el día me mantengo informado y también puedo ver el cielo azul que es muy hermoso\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso español\n",
    "mp3_file = r\"/media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/AudiosFiles//maximo_ventana_español.mp3\"  # Reemplaza con la ruta a tu archivo MP3\n",
    "texto = mp3_to_text_esp(mp3_file)\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4199d9a5-7bf2-4240-9231-50c57c9972e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/AudiosFiles//Record_kafka.wav\n",
      "una mañana tras un sueño intranquilo Gregorio samsa se despertó convertido en un monstruoso insecto estaba echado de espaldas sobre un duro caparazón y al lanzar la cabeza vio su vientre convexo y oscuro surcado por curvadas callosidades sobre el cual casi no se aguantaba la colcha que estaba a punto de descubrirse hasta el suelo numerosas patas penosamente delgadas en comparación al grosor normal de sus piernas se agitaban sin concierto que me ha ocurrido\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de uso español\n",
    "mp3_file = r\"/media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/AudiosFiles//Record_kafka.mp3\"  # Reemplaza con la ruta a tu archivo MP3\n",
    "texto = mp3_to_text_esp(mp3_file)\n",
    "print(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3d4951-e51e-446b-bddf-d487c8e7bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "KAFKA - La metamorfosis\n",
    "\n",
    "Una mañana, tras un sueño intranquilo, Gregorio Samsa se despertó convertido en un monstruoso insecto. Estaba echado de espaldas sobre un duro caparazón y, al alzar la cabeza, vio su vientre convexo y oscuro, surcado por curvadas callosidades, sobre el cual casi no se aguantaba la colcha, que estaba a punto de escurrirse hasta el suelo. Numerosas patas, penosamente delgadas en comparación al grosor normal de sus piernas, se agitaban sin concierto.\n",
    "-¿Qué me ha ocurrido?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a643c2-61fc-4122-aceb-a88228d1e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPEECH de microfono a TeXTO en tiempo real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6bb05c",
   "metadata": {},
   "source": [
    "# SPEECH de microfono a TeXTO en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123a084a-c14e-4f7c-89ad-1ac68254717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06f37918-633e-43df-acce-c90d236f6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Crear un reconocedor de voz\n",
    "recognizer = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad0f93c-ff2a-47a6-a4a0-09f2ec541c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib setup.c:547:(add_elem) Cannot obtain info for CTL elem (MIXER,'IEC958 Playback Default',0,0,0): No such file or directory\n",
      "ALSA lib setup.c:547:(add_elem) Cannot obtain info for CTL elem (MIXER,'IEC958 Playback Default',0,0,0): No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib pcm_dsnoop.c:601:(snd_pcm_dsnoop_open) unable to open slave\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib setup.c:547:(add_elem) Cannot obtain info for CTL elem (MIXER,'IEC958 Playback Default',0,0,0): No such file or directory\n",
      "ALSA lib setup.c:547:(add_elem) Cannot obtain info for CTL elem (MIXER,'IEC958 Playback Default',0,0,0): No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajustando para el ruido ambiente...\n",
      "Habla ahora:\n",
      "Has dicho: una mañana\n",
      "Has dicho: tras un sueño intranquilo\n",
      "Has dicho: Gregorio samsa se despertó\n",
      "Has dicho: convertido en monstruoso insecto\n",
      "No se pudo entender el audio.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     audio \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mlisten(source)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Intenta reconocer el audio usando Google Web Speech API\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mes-ES\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHas dicho: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sr\u001b[38;5;241m.\u001b[39mUnknownValueError:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/speech_recognition/recognizers/google.py:256\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[0;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[1;32m    251\u001b[0m request_builder \u001b[38;5;241m=\u001b[39m create_request_builder(\n\u001b[1;32m    252\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint, key\u001b[38;5;241m=\u001b[39mkey, language\u001b[38;5;241m=\u001b[39mlanguage, filter_level\u001b[38;5;241m=\u001b[39mpfilter\n\u001b[1;32m    253\u001b[0m )\n\u001b[1;32m    254\u001b[0m request \u001b[38;5;241m=\u001b[39m request_builder\u001b[38;5;241m.\u001b[39mbuild(audio_data)\n\u001b[0;32m--> 256\u001b[0m response_text \u001b[38;5;241m=\u001b[39m \u001b[43mobtain_transcription\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation_timeout\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[1;32m    261\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[1;32m    262\u001b[0m )\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_parser\u001b[38;5;241m.\u001b[39mparse(response_text)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/speech_recognition/recognizers/google.py:222\u001b[0m, in \u001b[0;36mobtain_transcription\u001b[0;34m(request, timeout)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestError(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecognition connection failed: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e\u001b[38;5;241m.\u001b[39mreason)\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:460\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:583\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m         chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:566\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_safe_read(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:526\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Usar el micrófono como fuente de entrada\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Ajustando para el ruido ambiente...\")\n",
    "    recognizer.adjust_for_ambient_noise(source)\n",
    "\n",
    "    print(\"Habla ahora:\")\n",
    "    while True:\n",
    "        try:\n",
    "            # Captura el audio en tiempo real\n",
    "            audio = recognizer.listen(source)\n",
    "\n",
    "            # Intenta reconocer el audio usando Google Web Speech API\n",
    "            text = recognizer.recognize_google(audio, language='es-ES')\n",
    "            print(f\"Has dicho: {text}\")\n",
    "\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"No se pudo entender el audio.\")\n",
    "        except sr.RequestError:\n",
    "            print(\"No se pudo conectar con el servicio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e054c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOSK de microfono a TeXTO en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f074c1-0074-4d82-8196-311d893ddccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3091b22f-a6dd-48a7-88e8-383d7023d7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOG (VoskAPI:ReadDataFiles():model.cc:213) Decoding params beam=13 max-active=7000 lattice-beam=6\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:216) Silence phones 1:2:3:4:5:6:7:8:9:10\n",
      "LOG (VoskAPI:RemoveOrphanNodes():nnet-nnet.cc:948) Removed 0 orphan nodes.\n",
      "LOG (VoskAPI:RemoveOrphanComponents():nnet-nnet.cc:847) Removing 0 orphan components.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:248) Loading i-vector extractor from /media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/modelo vosk/vosk-model-es-0.42/vosk-model-es-0.42/ivector/final.ie\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:183) Computing derived variables for iVector extractor\n",
      "LOG (VoskAPI:ComputeDerivedVars():ivector-extractor.cc:204) Done.\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:279) Loading HCLG from /media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/modelo vosk/vosk-model-es-0.42/vosk-model-es-0.42/graph/HCLG.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:297) Loading words from /media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/modelo vosk/vosk-model-es-0.42/vosk-model-es-0.42/graph/words.txt\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:308) Loading winfo /media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/modelo vosk/vosk-model-es-0.42/vosk-model-es-0.42/graph/phones/word_boundary.int\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:315) Loading subtract G.fst model from /media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/modelo vosk/vosk-model-es-0.42/vosk-model-es-0.42/rescore/G.fst\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:317) Loading CARPA model from /media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/modelo vosk/vosk-model-es-0.42/vosk-model-es-0.42/rescore/G.carpa\n",
      "LOG (VoskAPI:ReadDataFiles():model.cc:323) Loading RNNLM model from /media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/modelo vosk/vosk-model-es-0.42/vosk-model-es-0.42/rnnlm/final.raw\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.surround71\n",
      "ALSA lib setup.c:547:(add_elem) Cannot obtain info for CTL elem (MIXER,'IEC958 Playback Default',0,0,0): No such file or directory\n",
      "ALSA lib setup.c:547:(add_elem) Cannot obtain info for CTL elem (MIXER,'IEC958 Playback Default',0,0,0): No such file or directory\n",
      "ALSA lib setup.c:547:(add_elem) Cannot obtain info for CTL elem (MIXER,'IEC958 Playback Default',0,0,0): No such file or directory\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.hdmi\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.modem\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.phoneline\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
      "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
      "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habla ahora...\n",
      "{\n",
      "  \"text\" : \"una mañana tras un sueño intranquilo gregorio samsa se despertó convertido en un monstruoso insecto estaba echado de espaldas un indulto para su nieto alzar la cabeza vio sube entre convexo y oscuro surcado por curvadas callosidades sobre el cual\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"casi no se aguantaba la colcha que estaba a punto de escurrirse hasta el suelo\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"\"\n",
      "}\n",
      "{\n",
      "  \"text\" : \"numerosas patas penosamente delgadas en comparación al grosor grosor normal de sus piernas se agitaban sin concierto qué me ha ocurrido\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHabla ahora...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyaudio\n",
    "from vosk import Model, KaldiRecognizer\n",
    "\n",
    "# Descarga el modelo en español desde https://alphacephei.com/vosk/models\n",
    "model_path = r\"/media/sf_SHARE_VIRTUAL_MACHINE/AUDIOS/modelo vosk/vosk-model-es-0.42/vosk-model-es-0.42\"\n",
    "# Cargar el modelo de Vosk\n",
    "model = Model(model_path)\n",
    "# Configurar el micrófono y PyAudio\n",
    "recognizer = KaldiRecognizer(model, 16000)\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# Iniciar el micrófono\n",
    "stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, frames_per_buffer=8000)\n",
    "stream.start_stream()\n",
    "\n",
    "print(\"Habla ahora...\")\n",
    "\n",
    "while True:\n",
    "    data = stream.read(4000)\n",
    "    if len(data) == 0:\n",
    "        break\n",
    "    if recognizer.AcceptWaveform(data):\n",
    "        result = recognizer.Result()\n",
    "        print(result)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6768ae",
   "metadata": {},
   "source": [
    "# WHISPER de microfono a Grabacion a Texto en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5e60eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install whisper pydub audioread\n",
    "#!pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "261fcff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando...\n",
      "Grabación finalizada.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stevens/.local/lib/python3.10/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "/home/stevens/.local/lib/python3.10/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto transcrito:\n",
      " Una mañana, tras un sueño, intranquilo, Gregorio Sansa se despertó convertido en un monstruo sin secto. Estaba echado de espalda sobre un duro caparazón y a la de Sarla Cabeza, yo soy entre convexo y escuro. Surcado por curvasca, yo decía, sobre el cual casi no se ha aguantado a la colcha, que estaba a punto de escurrirse hasta el sol. Numeró esas patas, pero solamente el gada sin comparación al grueso, normal de sus piernas agitaban sin concierto. ¿Qué me ha ocurrido? ¿Qué?\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import pyaudio\n",
    "import wave\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Configuración de la grabación\n",
    "CHUNK = 1024;\n",
    "FORMAT = pyaudio.paInt16;\n",
    "CHANNELS = 1;\n",
    "RATE = 16000;\n",
    "RECORD_SECONDS = 60;  # Tiempo de grabación en segundos\n",
    "WAV_OUTPUT_FILENAME = \"temp_audio.wav\";\n",
    "\n",
    "def record_audio():\n",
    "    # Inicializar PyAudio\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Configurar el micrófono\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Grabando...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # Grabar audio durante el tiempo especificado\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Grabación finalizada.\")\n",
    "\n",
    "    # Detener y cerrar el stream de audio\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Guardar el audio en un archivo WAV\n",
    "    wf = wave.open(WAV_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "\n",
    "def transcribe_audio_with_whisper():\n",
    "    # Cargar el modelo Whisper\n",
    "    model = whisper.load_model(\"base\")  # Puedes usar otros modelos como \"small\", \"medium\", \"large\"\n",
    "    \n",
    "    # Transcribir el archivo de audio grabado\n",
    "    result = model.transcribe(WAV_OUTPUT_FILENAME)\n",
    "    \n",
    "    # Imprimir la transcripción\n",
    "    print(\"Texto transcrito:\")\n",
    "    print(result[\"text\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    record_audio()\n",
    "    transcribe_audio_with_whisper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4595128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
